{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online labor markets and worker selection: A systematic review\n",
    "\n",
    "(vignette)\n",
    "\n",
    "G. Wagner, J. Prester, R. Lukyanenko, G. Paré\n",
    "\n",
    "Building on the C5-DM framework for data management in literature reviews ([Wagner et al. 2026](#ref-WagnerEtAl2026)), this vignette illustrates how data management principles can be implemented in a literature review. The framework foregrounds data conceptualization, collection, curation, control, and consumption as foundational activities that shape the transparency, reliability, and reuse of literature review outcomes. The vignette is organized into two complementary parts. The middle column presents a systematic literature review following established reporting conventions. The right column explains how the manuscript is internally grounded in explicit data management decisions aligned with the C5-DM framework, adding an interactive layer of annotations that makes these decisions visible. The vignette thus serves as a concrete illustration of good data management practice in literature reviews—one that readers can follow directly in their own work while also sharpening their understanding of what to look for when evaluating other software solutions and data management approaches.\n",
    "\n",
    "> **5C-DM Framework**\n",
    ">\n",
    "> This column explains how the data management principles are implemented. ⬇️\n",
    ">\n",
    "> <!-- Click on the buttons for an explanation. -->\n",
    "\n",
    "## Plan\n",
    "\n",
    "This review focuses on worker selection decisions in online labor markets. In line with qualitative systematic reviews ([Higgins and Green 2008](#ref-HigginsGreen2008); [Smith et al. 2011](#ref-SmithEtAl2011)), it aims at collecting evidence from prior empirical studies and aggregating it.\n",
    "\n",
    "The review is conducted using a <a href=\"https://github.com/fs-ise/C5-DM-vignette\" target=\"_blank\">shared GitHub repository</a>, which was synchronized locally by the team.\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"curate-version-control.html\"> ⧉ Version-control data (Curate). </a>\n",
    "\n",
    "## Search\n",
    "\n",
    "We specified search strategies for the Crossref and DBLP application programming interfaces (APIs)[1] using the core keyword *microsourcing* and a set of semantically related synonyms. We also reused samples from prior reviews ([Wagner, Prester, and Paré 2021](#ref-WagnerPresterPare2021); [Fiers 2023](#ref-Fiers2023)). The resulting query formulations were systematically tabulated to document the conceptual scope of the search and to enable consistent execution across data sources (see <a href=\"#tbl-search-overview\" class=\"quarto-xref\">Table 1</a>).\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"control-standard-formats.html\"> ⧉ Use standard file formats (Control). </a>\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"conceptualize-raw-primary.html\"> ⧉ Link raw and primary records (Conceptualize). </a>\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"consume-reuse-prior-review.html\"> ⧉ Reuse prior review data (Consume). </a>\n",
    "\n",
    "``` python\n",
    "import json\n",
    "from pathlib import Path\n",
    "from urllib.parse import quote\n",
    "\n",
    "SEARCH_DIR = Path(\"data/search\")\n",
    "\n",
    "def md_link(text: str, target_path: str) -> str:\n",
    "    target_path_posix = Path(target_path).as_posix()\n",
    "    url = target_path_posix\n",
    "    return f\"[{text}]({url})\"\n",
    "\n",
    "\n",
    "json_files = sorted(SEARCH_DIR.glob(\"*.json\"))\n",
    "\n",
    "rows = []\n",
    "for jf in json_files:\n",
    "    try:\n",
    "        data = json.loads(jf.read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    label = (data.get(\"label\") or jf.stem).strip()\n",
    "    results_path = (data.get(\"search_results_path\") or \"\").strip()\n",
    "\n",
    "    # Render links in the same \"data/search/...\" style as in your manual table\n",
    "    json_link_target = f\"data/search/{jf.name}\"\n",
    "    search_strategy_cell = md_link(jf.name, json_link_target)\n",
    "\n",
    "    search_results_cell = (\n",
    "        md_link(Path(results_path).name, results_path)\n",
    "        if results_path\n",
    "        else \"\"\n",
    "    )\n",
    "\n",
    "    rows.append((label, search_strategy_cell, search_results_cell))\n",
    "\n",
    "print(\"::: {#tbl-search-overview}\")\n",
    "print(\"Table: Overview of search strategies and results.\\n\")\n",
    "print(\"| Source | Search strategy | Search results |\")\n",
    "print(\"|:--------|:-----------------|:----------------|\")\n",
    "for s, strat, res in rows:\n",
    "  print(f\"| {s} | {strat} | {res} |\")\n",
    "print(\"\\n:::\")\n",
    "```\n",
    "\n",
    "| Source | Search strategy | Search results |\n",
    "|:---|:---|:---|\n",
    "| Prior review: Fiers ([2023](#ref-Fiers2023)) | [Fiers2023_search_history.json](data/search/Fiers2023_search_history.json) | [Fiers2023.csv](data/search/Fiers2023.csv) |\n",
    "| Prior review: Wagner, Prester, and Paré ([2021](#ref-WagnerPresterPare2021)) | [WagnerPresterPare2021_search_history.json](data/search/WagnerPresterPare2021_search_history.json) | [WagnerPresterPare2021.bib](data/search/WagnerPresterPare2021.bib) |\n",
    "| Crossref (API search) | [crossref_search_history.json](data/search/crossref_search_history.json) | [crossref.bib](data/search/crossref.bib) |\n",
    "| DBLP (API search) | [dblp_search_history.json](data/search/dblp_search_history.json) | [dblp.bib](data/search/dblp.bib) |\n",
    "\n",
    "Table 1: Overview of search strategies and results.\n",
    "\n",
    "[1] For the illustration, we relied on open-access API-searches, because licensing issues do not allow for publication of raw data exported from databases like WOS or EBSCO."
   ],
   "id": "3d5e3d47-0318-436b-b6dd-1a17a235b582"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The search strategies are stored in JSON format together with the raw data files in the <a href=\"https://github.com/fs-ise/C5-DM-vignette/tree/main/data/search\" target=\"_blank\">data/search</a> directory, in line with the standard of Haddaway et al. ([2022](#ref-HaddawayRethlefsenDaviesEtAl2022)).\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"collect-transparency-coverage.html\"> ⧉ Report database coverage (Collect). </a>\n",
    "\n",
    "## Dedupe\n",
    "\n",
    "Metadata was prepared using CoLRev and extensions ([Wagner and Prester 2025](#ref-WagnerPrester2025)). <!--\n",
    "Preparation changes are in the [prep commits](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+prep&type=commits){target=_blank}.\n",
    " or link to individual commit? https://github.com/fs-ise/C5-DM-vignette/commit/051e115fff389f209afb9a4fbe77e6a33271264c \n",
    "\n",
    "\n",
    "::: {.callout-note title=\"Manually supervised task — Import and prepare metadata\" collapse=true}\n",
    "**Trigger:** Records with `colrev_status = {md_retrieved}` in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib)   \n",
    "**Responsible:** Review coordinator  \n",
    "\n",
    "**Commands:**\n",
    "```sh\n",
    "# 1) Load: convert raw inputs to BibTeX entries in data/records.bib\n",
    "colrev load\n",
    "\n",
    "# 2) Prep: automated normalization/enrichment (may advance most records)\n",
    "colrev prep\n",
    "\n",
    "# 3) Prep-man: resolve remaining flags manually\n",
    "colrev prep-man\n",
    "```\n",
    "\n",
    "**Output (in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib)):**\n",
    "\n",
    "- Records are converted to BibTeX and advance from `md_retrieved` → `md_imported` → `md_prepared`.\n",
    "- Records that cannot be prepared automatically are flagged as `md_needs_manual_preparation` and must be resolved before they are set to `md_prepared`.\n",
    "\n",
    "**Validation:** Run `colrev validate` after committing changes.  \n",
    "**History filters:** [load](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+load&type=commits) · [prep](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+prep&type=commits) · [prep-man](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+prep-man&type=commits)\n",
    ":::\n",
    "--> Deduplication was done using BibDedupe ([Wagner 2024](#ref-Wagner2024)). <!--\n",
    "Deduplication changes are in the [dedupe commits](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+dedupe&type=commits){target=_blank}.\n",
    "or link to individual commit? https://github.com/fs-ise/C5-DM-vignette/commit/c22178d10fb90954d681f428fc5b08c72b5e6d48 -->\n",
    "\n",
    "> **Manually supervised task — Deduplicate**\n",
    ">\n",
    "> **Trigger:** Records in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib) are in `colrev_status = {md_prepared}`  \n",
    "> **Responsible:** Review coordinator  \n",
    "> **Command:**\n",
    ">\n",
    "> ``` sh\n",
    "> colrev dedupe\n",
    "> ```\n",
    ">\n",
    "> **Output (in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib)):** Duplicates resolved and records set to `md_processed` (ready for prescreen)  \n",
    "> **Validation:** Run `colrev validate` after committing  \n",
    "> **History filter:** [dedupe](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+dedupe&type=commits)\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"collect-prepare.html\"> ⧉ Prepare (meta)data (Collect). </a>\n",
    "\n",
    "<!--\n",
    "Dedupe changes were validated using the max-diff strategy (`colrev validate XXXX`).\n",
    "Preparation changes were validated using the max-diff strategy (`colrev validate XXXX`).\n",
    "-->\n",
    "\n",
    "## Prescreen\n",
    "\n",
    "For prescreening, we tested a new *LLM-based prescreened*. <!-- [llm-prescreener](temp_file.txt){target=_blank} --> Comparison with prescreening decisions of GW showed low reliability with the llm-prescreener. Results were therefore reverted and a fully manual prescreen was implemented.\n",
    "\n",
    "<!--\n",
    "TODO:\n",
    "- tested...  in [ref](temp_file.txt){target=_blank}\n",
    "- (command + kappa)\n",
    "- results were reverted: ([ref](temp_file.txt))\n",
    "- This could also be done in a separate branch, or the changes could be undone using a hard git reset. -->\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"control-evaluate-changes.html\"> ⧉ Evaluate changes (Control). </a>\n",
    "\n",
    "> **Manually supervised task — Prescreen records**\n",
    ">\n",
    "> **Trigger:** [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib) updated  \n",
    "> **Responsible:** Two independent coders (GW and JP)  \n",
    "> **Protocol:** screening procedures and criteria (see `protocol/screening.md`)  \n",
    "> **Output:** `records_screened.bib`  \n",
    "> **History filter:** [prescreen](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+prescreen&type=commits&p=1)\n",
    "\n",
    "For full-text screening, PDF documents were retrieved and prepared.\n",
    "\n",
    "> **Manually supervised task — Retrieve and prepare full texts**\n",
    ">\n",
    "> **Trigger:** Records in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib) with `colrev_status = {rev_prescreen_included}`  \n",
    "> **Responsible:** Review coordinator (pdf-get/pdf-prep) and individual reviewer (pdf-get-man/pdf-prep-man)\n",
    ">\n",
    "> **Commands:**\n",
    ">\n",
    "> ``` sh\n",
    "> # 1) pdf-get: automated retrieval and linking of PDFs\n",
    "> colrev pdf-get\n",
    ">\n",
    "> # 2) pdf-get-man: manual retrieval for remaining missing PDFs\n",
    "> colrev pdf-get-man\n",
    ">\n",
    "> # 3) pdf-prep: automated PDF preparation (OCR/text extraction/checks)\n",
    "> colrev pdf-prep\n",
    ">\n",
    "> # 4) pdf-prep-man: manual fixes for remaining problematic PDFs\n",
    "> colrev pdf-prep-man\n",
    "> ```\n",
    ">\n",
    "> **Output (in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib)):**\n",
    ">\n",
    "> -   After retrieval, records are updated with `file = {data/pdfs/<...>.pdf}` and advanced to `colrev_status = {pdf_imported}`.\n",
    "> -   After preparation, records are advanced to `colrev_status = {pdf_prepared}`.\n",
    "> -   Failures are flagged as `pdf_needs_manual_preparation` and must be resolved via `colrev pdf-prep-man` before they are set to `pdf_prepared`.\n",
    ">\n",
    "> **Notes:** PDF retrieval depends on institutional access, licensing constraints, and rate limits.  \n",
    "> **History filters:** [pdf-get](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+pdf-get&type=commits) · [pdf-get-man](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+pdf-get-man&type=commits) · [pdf-prep](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+pdf-prep&type=commits) · [pdf-prep-man](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+pdf-prep-man&type=commits)\n",
    "\n",
    "Records were screened independently, as described in the following.\n",
    "\n",
    "> **Manual task — Screen full texts**\n",
    ">\n",
    "> **Trigger:** Records in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib) with `colrev_status = {pdf_prepared}`  \n",
    "> **Responsible:** Two independent coders (GW and JP)  \n",
    "> **Protocol:** full-text screening procedures and criteria (see `protocol/fulltext_screening.md`)\n",
    ">\n",
    "> **Process:**\n",
    ">\n",
    "> -   Each coder screens the full text independently and records an inclusion/exclusion decision.\n",
    "> -   Disagreements are resolved through discussion (or third-coder arbitration, if needed).\n",
    "> -   Decisions and reasons are logged in the record fields (e.g., `screening_criteria`, `screening_decision`, `screening_reason`) according to the protocol.\n",
    ">\n",
    "> **Output (in [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib)):**\n",
    ">\n",
    "> -   Included full texts: `colrev_status = {rev_screen_included}`\n",
    "> -   Excluded full texts: `colrev_status = {rev_screen_excluded}` (with documented exclusion reason)\n",
    ">\n",
    "> **History filter:** [screen](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+screen&type=commits)\n",
    "\n",
    "<!-- Screen: fulltext documents were shared in a protected drive (link to Dropbox) -->\n",
    "\n",
    "## Data extraction\n",
    "\n",
    "In line with the methodology of systematic reviews ([Higgins and Green 2008](#ref-HigginsGreen2008); [Smith et al. 2011](#ref-SmithEtAl2011)), we selected structured data forms to extract evidence from the studies.\n",
    "\n",
    "> **Manual task — Extract evidence**\n",
    ">\n",
    "> **Trigger:** [data/records.bib](https://github.com/fs-ise/C5-DM-vignette/blob/main/data/records.bib) updated  \n",
    "> **Responsible:** Two independent coders (GW and JP)  \n",
    "> **Protocol:** data extraction form and protocol (see `protocol/data_extraction.md`)  \n",
    "> **Output:** `extracted_evidence.yaml`  \n",
    "> **History filter:** [data](https://github.com/search?q=repo%3Afs-ise%2FC5-DM-vignette+data&type=commits&p=1)\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"curate-align-data-with-methods.html\"> ⧉ Align data with methods (Curate). </a>\n",
    "\n",
    "## Synthesis\n",
    "\n",
    "The narrative synthesis is in the <a href=\"https://github.com/fs-ise/C5-DM-vignette/blob/main/data/data/paper.md\" target=\"_blank\">paper document</a> in Markdown format, allowing for larger teams to work on the same document (similar to the [covid19-review](https://github.com/greenelab/covid19-review)). The current status of the project is automatically updated with every change and reflected in the PRISMA chart (<a href=\"#fig-prisma\" class=\"quarto-xref\">Figure 1</a>, in line with the recommendations of Page et al. ([2021](#ref-PageMcKenzieBossuytEtAl2021)))."
   ],
   "id": "9179573e"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "fig-height": 6,
    "fig-width": 10
   },
   "outputs": [
    {
     "output_type": "display_data",
     "metadata": {},
     "data": {}
    }
   ],
   "source": [
    "from prisma_flow_diagram import plot_prisma_from_records\n",
    "\n",
    "plot_prisma_from_records(records_path=\"/home/gerit/ownCloud/data/literature_reviews/LRDM/C5-DM-vignette/data/records.bib\", show=True)"
   ],
   "id": "cell-fig-prisma"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"#tbl-evidence\" class=\"quarto-xref\">Table 2</a> provides summary of extracted evidence."
   ],
   "id": "1c264e3e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "message": false
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "yaml_path = Path(\"data/evidence_platform_work_biases.yml\")\n",
    "\n",
    "with yaml_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    doc = yaml.safe_load(f)\n",
    "\n",
    "df = pd.DataFrame(doc.get(\"papers\", []))\n",
    "\n",
    "cols = [\n",
    "    \"study_id\", \"citation_key\", \"year\", \"platform\", \"platform_type\",\n",
    "    \"method\", \"data\", \"sample\",\n",
    "    \"bias_type\", \"bias_mechanism\",\n",
    "    \"outcome_affected\", \"evidence_level\", \"direction_of_bias\",\n",
    "    \"key_result\", \"notes\",\n",
    "]\n",
    "df = df[[c for c in cols if c in df.columns]]\n",
    "\n",
    "df[\"year\"] = pd.to_numeric(df.get(\"year\"), errors=\"coerce\").astype(\"Int64\")\n",
    "df = df.sort_values([\"bias_type\", \"evidence_level\", \"year\"], na_position=\"last\").reset_index(drop=True)\n",
    "\n",
    "compact_cols = [\n",
    "    \"citation_key\", \"platform_type\", \"bias_type\",\n",
    "    \"outcome_affected\", \"key_result\"\n",
    "]\n",
    "df_compact = df[compact_cols].rename(columns={\"citation_key\": \"study\"})\n",
    "df_compact"
   ],
   "id": "eb78086b-f001-4b8a-91c0-f3b712a1839e"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "\n",
    "@fig-aggregated-evidence aggregates the evidence.\n",
    ":::\n",
    "\n",
    "::: {#cell-fig-aggregated-evidence .cell message='false' execution_count=4}\n",
    "``` {.python .cell-code}\n",
    "weights = {\n",
    "    \"weak\": 1,\n",
    "    \"moderate\": 2,\n",
    "    \"moderate_to_strong\": 3,\n",
    "    \"strong\": 4\n",
    "}\n",
    "\n",
    "df_w = df.copy()\n",
    "df_w[\"evidence_weight\"] = df_w[\"evidence_level\"].map(weights).fillna(0)\n",
    "\n",
    "score = (\n",
    "    df_w.groupby(\"bias_type\")[\"evidence_weight\"]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "ax = score.plot(kind=\"barh\", figsize=(8, 3))\n",
    "ax.set_title(\"Weighted evidence score by bias type (higher = more/stronger evidence)\")\n",
    "ax.set_xlabel(\"Bias type\")\n",
    "ax.set_ylabel(\"Weighted score\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "::: {.cell-output .cell-output-display}\n",
    "![Aggregated evidence (generated from [TODO](link))](index_files/figure-html/fig-aggregated-evidence-output-1.png){#fig-aggregated-evidence width=782 height=278}\n",
    ":::\n",
    ":::\n",
    "\n",
    "\n",
    ":::{#8f8ed755 .cell .markdown}\n",
    "-->\n",
    "\n",
    "## Data availability\n",
    "\n",
    "To make the review reusable, the data was published on GitHub under the [CC BY 4.0](https://github.com/fs-ise/C5-DM-vignette/blob/main/LICENSE.txt) license[1].\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"curate-share-data.html\"> ⧉ Share data for reuse (Curate). </a>\n",
    "\n",
    "<a class=\"pill\" target=\"_blank\"\n",
    "   href=\"consume-select-open-licenses.html\"> ⧉ Select open licenses (Consume). </a>\n",
    "\n",
    "# References\n",
    "\n",
    "[1] Indexing in SYNERGY, SearchRXiv is planned once the review progresses beyond the *illustration* stages."
   ],
   "id": "84996596"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiers, Fien. 2023. “Inequality and Discrimination in the Online Labor Market: A Scoping Review.” *New Media & Society* 25 (12): 3714–34. <https://doi.org/10.1177/14614448221128379>.\n",
    "\n",
    "Haddaway, Neal R., Melissa L. Rethlefsen, Melinda Davies, Julie Glanville, Bethany McGowan, Kate Nyhan, and Sarah Young. 2022. “A Suggested Data Structure for Transparent and Repeatable Reporting of Bibliographic Searching.” *Campbell Systematic Reviews* 18 (4): 1–12. <https://doi.org/10.1002/CL2.1288>.\n",
    "\n",
    "Higgins, Julian PT, and Sally Green. 2008. *Cochrane Handbook for Systematic Reviews of Interventions: Cochrane Book Series*. John Wiley & Sons, Ltd., Chichester, UK.\n",
    "\n",
    "Page, Matthew J., Joanne E. McKenzie, Patrick M. Bossuyt, Isabelle Boutron, Tammy C. Hoffmann, Cynthia D. Mulrow, Larissa Shamseer, et al. 2021. “The PRISMA 2020 Statement: An Updated Guideline for Reporting Systematic Reviews.” *Systematic Reviews* 10 (1). <https://doi.org/10.1186/S13643-021-01626-4>.\n",
    "\n",
    "Smith, Valerie, Declan Devane, Cecily M Begley, and Mike Clarke. 2011. “Methodology in Conducting a Systematic Review of Systematic Reviews of Healthcare Interventions.” *BMC Medical Research Methodology* 11 (1): 15. <https://doi.org/10.1186/1471-2288-11-15>.\n",
    "\n",
    "Wagner, Gerit. 2024. “BibDedupe: An Open-Source Python Library for Bibliographic Record Deduplication.” *Journal of Open Source Software* 9 (97): 6318. <https://doi.org/10.21105/JOSS.06318>.\n",
    "\n",
    "Wagner, Gerit, and Julian Prester. 2025. “CoLRev: An Open-Source Environment for Collaborative Reviews.” <https://github.com/CoLRev-Environment/colrev>.\n",
    "\n",
    "Wagner, Gerit, Julian Prester, Roman Lukyanenko, and Guy Paré. 2026. “Data Management in Literature Reviews: The C5-DM Framework.” *Research Synthesis Methods (Under Review)*.\n",
    "\n",
    "Wagner, Gerit, Julian Prester, and Guy Paré. 2021. “Exploring the Boundaries and Processes of Digital Platforms for Knowledge Work: A Review of Information Systems Research.” *The Journal of Strategic Information Systems* 30 (4): 101694. <https://doi.org/10.1016/j.jsis.2021.101694>."
   ],
   "id": "7277352f-8062-4724-83fa-e9797243828c"
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {}
}
